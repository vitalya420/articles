# DDoS HTTP пакетами для чайників

Ця стаття допоможе зрозуміти, як сервери опрацьовують HTTP-запити, і пояснить, як надмірна кількість запитів може призвести до відмови в обслуговуванні.


## Забити мережевий трафік

На перший погляд, здається, що найпростіший спосіб задудосити сервер — це **забити мережевий трафік** до такої міри, що нові пакети почнуть оброблятися дуже повільно або зовсім відхилятися. Це має сенс, адже встановлення кожного нового з'єднання та **SSL Handshake** потребують обміну кількома пакетами між клієнтом і сервером.  

Але тут є нюанс.  
Сучасні сервери в датацентрах мають пропускну здатність близько **10 гігабіт на секунду** або навіть більше. Для того щоб вичерпати таку пропускну здатність, потрібна неймовірно велика кількість запитів на секунду.  

Куди ефективніше — навантажувати вихідну пропускну здатність сервера, адже кожна відповідь може бути значно важчою за вхідний запит. Наприклад, звичайний запит `GET / HTTP/1.1\r\n\r\n` розміром 18 байт, може згенерувати відповідь в декілька кілобайт.

## Вичерпення Worker'ів

На веб-сервері майже завжди стоїть **reverse proxy**, наприклад, **Nginx** (один із найпопулярніших), **Apache HTTP Server (httpd)** чи інші. Основна функція reverse proxy — приймати вхідні запити та передавати їх далі на бекенд.  

Але кількість запитів, які reverse proxy може обробити одночасно, **не є безмежною**.  
Кожне з'єднання обслуговується окремим воркером або потоком, і їхня кількість обмежена налаштуваннями сервера та системними ресурсами.  

При надмірній кількості з'єднань сервер просто **не зможе виділити новий воркер**, і нові запити залишаться без обробки. Це призведе до **відмови в обслуговуванні** для нових користувачів.  


## Вичерпання кількості портів

Коли запит доходить до **Reverse Proxy**, він перенаправляється на бекенд-сервер. Важливо розуміти, що бекенд отримує з'єднання не від кінцевого користувача, а від локальної адреси, наприклад, **10.0.0.2**. Ця адреса може бути частиною внутрішньої мережі Docker або Kubernetes.

І може виникнути **проблема 65 тисяч з'єднань**. Це обмеження на кількість одночасних з'єднань, яке зазвичай становить **65 536 портів** для кожної IP-адреси. Якщо всі порти будуть зайняті, нові з'єднання просто не зможуть бути встановлені, і сервер перестане відповідати. 

Така проблема може виникнути у таких випадках:
  1. **Довге очікування відповіді від бекенда** — бекенд "думає" занадто довго, тримаючи з'єднання відкритим.  
  2. **Велика кількість запитів одночасно** — це може швидко вичерпати всі доступні порти.

Ця проблема, звичайно, вирішується досить просто — використанням **UNIX-сокетів** замість TCP-з'єднань. UNIX-сокети не мають обмеження на кількість портів, що дозволяє уникнути ліміту в 65 тисяч з'єднань.

Проте навіть при використанні UNIX-сокетів серверу все одно потрібні **системні виклики**, щоб передати кожен запит. 

## Вичерпення оперативної пам'яті

Уявіть ситуацію: **100 з'єднань** відправляють по **1 мегабайту даних**. Сервер повинен десь зберігати ці дані, і зазвичай він робить це в **оперативній пам'яті**. На цьому етапі все ще виглядає прийнятно.

Але тепер уявіть, що кількість з'єднань зростає до **1000**, і кожне з них передає по **5 мегабайт даних**. Це вже **~4 гігабайти пам'яті**! Якщо оперативна пам’ять закінчується, у Linux виникає **Out of Memory (OOM)** ситуація.  

І як діє Linux у цьому випадку?  
Він просто **вбиває процес**, який споживає найбільше пам’яті, щоб звільнити ресурси. У нашому випадку це буде веб-сервер або бекенд-процес, що призводить до **повного припинення обслуговування**. Однак, супервізор процес перезапустить.

## Потокове голодування

Ще однією серйозною проблемою є **потокове голодування**. Якщо велика кількість одночасних запитів передається на бекенд, серверу може просто **не вистачити ресурсів** для обробки всіх цих запитів.  

У такій ситуації кожен запит вимагає обробки, але через обмежені ресурси **операційна система починає постійно перемикати контекст** між потоками. Це перемикання є **дуже дорогим завданням**.

У результаті **більша частина часу витрачається на перемикання контексту**, а не на реальну обробку запитів. Це знижує продуктивність і може призвести до повного зависання сервера.  

Якщо сервер не використовує потоки, а натомість асинхронність, циклу подій потрібно перемикатися між ними в порядку пріоритету. Якщо таких завдань дуже багато, то перемикання між цими асинхронними функціями буде сповільнюватися.

## Обмеження в кількості системних викликів.

Уявімо таку ситуацію: клієнт надсилає запит на сервер, щоб авторизуватися. Давайте порахуємо, що потрібно зробити клієнту:  

1. Встановити з’єднання.  
2. Виконати **SSL handshake**.  
3. Записати запит у **socket**.  
4. Дочекатися відповіді від сервера.  

А тепер розглянемо, що повинен зробити сервер у відповідь:  

1. **Прийняти з’єднання**.  
2. Виконати **SSL handshake**.  
3. **epoll** для моніторингу з’єднання.  
4. Відкрити з’єднання з бекендом і передати запит.  
5. Бекенд має **прочитати запит** і з’єднатися з базою даних.  
6. База даних виконує **читання або запис**, після чого бекенд формує відповідь.  

Як бачимо, **кількість системних викликів на сервері значно більша**, ніж на стороні клієнта. І хоча сучасні процесори здатні обробляти величезну кількість системних викликів, це не безмежний ресурс.  

**При великому навантаженні навіть найпотужніший процесор може "лягти"**, вичерпавши можливості обробки системних викликів у секунду.  

## "Удар по гаманцю"

Хостинг-провайдери, такі як **Google Cloud**, **AWS**, **DigitalOcean** та інші, мають **квоти на вихідний трафік**. Наприклад, у DigitalOcean додаткова плата за перевищення квоти становить **$0.01 за 1 гігабайт**.  

Як це можна використати? Достатньо знайти **великий файл** на сервері та **завантажувати його багато разів**. Таким чином, ми швидко вичерпаємо квоту на вихідний трафік.  

**Досвід та експерименти показують**, що перевищити цю квоту можна **дуже швидко**, завдавши фінансових збитків власнику сервера.  

## Визначення конфігурації сервера
Важливо визначити такі параметри, як **connection timeout**, **client max body** та кількість запитів, які можуть бути передані в одному з'єднанні (через **Connection: keep-alive**).

### 1. Connection Timeout

Знаючи значення **connection timeout**, можна спланувати стратегію для відкриття великої кількості з'єднань. Наприклад, якщо тайм-аут складає **1 хвилину**, можна відправити запит за секунду до того, як сервер закриє з'єднання. В цей час можна відкривати ще сотні або тисячі з'єднань. Але варто пам'ятати про обмеження на кількість з'єднань, адже **65 тисяч портів** з однієї IP-адреси — це ліміт.

### 2. Client Max Body
Другим важливим параметром є **client max body**. Знаючи максимальний розмір тіла запиту, можна навантажити сервер, відправляючи найбільші можливі файли чи дані, поки сервер не закриє з'єднання через перевищення цього ліміту. І тут варто також враховувати **connection timeout** для максимального використання доступного часу.

### 3. Тестування навантаження на процесор
Інший варіант — це відправлення великого **JSON** об'єкта для використання **процесорного часу на парсинг**. Знаючи, як довго сервер обробляє цей запит, можна визначити кількість доступних ядер процесора. Як це зробити? Просто!

1. Спочатку відправляємо **JSON**, який парситься протягом, наприклад, 2 секунд.
2. Потім відправляємо цей самий JSON у паралельних з'єднаннях і дивимося, чи збільшиться час обробки. Якщо час зростає, це може означати, що серверу не вистачає ядер процесора для паралельної обробки запитів.

### Важливість
Знаючи конфігурацію сервера та ресурси хостинг-провайдера, можна сформувати більш ефективний план для атаки або для оцінки стійкості сервера до таких навантажень.


## Експрермент

Аби щось довести чи спростувати, потрібно спробувати. Для цього було розроблено невелике веб API з кількома ендпоїнтами:

- `/hit1` — запити до цього ендпоїнта записуються в **Redis**. Кожні 10 секунд **Celery** масово переносить ці записи в базу даних.  
- `/hit2` — запити одразу записуються безпосередньо в **базу даних**.  

### Налаштування середовища  
Це все працюватиме на комп'ютері із **8 CPU ядрами**. Атака буде проводитись з іншого фізичного пристрою в локальній мережі.

Спробуємо навантажити сервер та порівняємо продуктивність і зробимо висновки.  

### Технічні деталі  
- **Бекенд** написаний на **Python** із використанням **Sanic Web Framework**.  
- Використовуються **Sanic Workers**, як рекомендовано в офіційній документації (під час експериментів **Uvicorn** демонстрував меншу швидкодію).  
- **База даних** — **PostgreSQL 17**.  
- SSL сертифікати присутні.

### Запускаємо експеримент  
На Python ми створили скрипт, який відправляє **10 000 запитів** на `/hit2`. Для цього використовується бібліотека **aiohttp**, яка дозволяє асинхронно відправляти запити з мінімальним споживанням ресурсів на стороні клієнта.  

#### Результати `/hit2`
Скрипт майже не навантажив наш комп’ютер, але сервер із **8 ядрами** завантажився практично на **100%**. На графіку видно кількість записів у базу даних.  
Як можна побачити, сервер рідко коли обробляє **понад 600 запитів на секунду**.

![hit2](https://github.com/vitalya420/articles/blob/main/images/hits1_1.png?raw=true)
![hit2cpu](https://github.com/vitalya420/articles/blob/main/images/first.png?raw=true)

#### Результати `/hit1`
Далі ми протестували запити на **`/hit1`**, де запис у базу даних відбувається раз на **10 секунд** за допомогою **Celery**.  

- **Менше навантаження на сервер:** процесор нашого сервера не завантажився так сильно, як у випадку з `/hit2`.  
- **Вища продуктивність:** на графіку чітко видно, що в одну секунду сервер обробив **3250 запитів**.  

![hit1](https://github.com/vitalya420/articles/blob/main/images/hits1_2.png?raw=true)
![hit1](https://github.com/vitalya420/articles/blob/main/images/second.png?raw=true)

#### Висновки до цього експеримента
- **Флудити просто так у випадкове місце — неефективно.** Навіть велика кількість запитів може не створити значного навантаження на сервер.  
- **Набагато ефективніше знайти слабке місце в архітектурі.** У нашому випадку `/hit2` безпосередньо пише в базу даних і стає "вузьким місцем", тоді як `/hit1` працює через Celery і краще справляється з навантаженням.


### Відкриваємо велику кількість з'єднань  

За допомогою Python ми створили скрипт, який відкриває велику кількість з'єднань і тримає їх активними якомога довше. Це вже нагадує **Slowloris-атаку**, яка спрямована на вичерпання ресурсів сервера.  

**Як відкрити багато з'єднань? Ось кілька підказок:**  

- **Дізнайтесь таймаут сервера:** важливо розуміти, скільки часу сервер тримає з'єднання відкритим.  
- **Створюйте групи з'єднань:** відкривайте багато з'єднань і організуйте їх у групи для кращого керування.  
- **Надсилайте запит частинами:** відправляйте дані за декілька секунд до завершення таймауту, щоб з'єднання залишалось активним.  
- **Знайдіть "дешевий" запит:** оберіть той запит, який займає мінімум ресурсів і обробляється довше.  

![How2Connections](https://github.com/vitalya420/articles/blob/main/images/image2.png?raw=true)

#### Що відбулося?  
В результаті nginx вичерпав свої воркери. Це призвело до того, що нові з'єднання не могли бути встановлені.  

Звісно, я міг краще налаштувати nginx, але така ситуація може трапитися і на **будь-якому сервері**! Особливо якщо конфігурація не була оптимізована або не передбачала захист від такого типу атак.  

![Nginx is dead](https://github.com/vitalya420/articles/blob/main/images/nginx.png?raw=true)

## Висновок

DoS та DDoS атаки методом HTTP флуду дійсно можуть бути досить ефективними. Однак важливо не просто бездумно відправляти запити, а спершу зрозуміти, де знаходиться вузьке горло сервера. Наприклад, це може бути **запис в базу даних при кожному запиті** або ендпоїнт, який виконує складну обчислювальну роботу.  

Ця стаття була написана, щоб показати, як можна навантажити сервер на рівні **процесора**, і зокрема, як знаходити та експлуатувати слабкі місця в архітектурі сервера та додатків. Якщо з'ясувати, де саме сервер потребує найбільше ресурсів, можна значно ефективніше проводити навантажувальні атаки.


### Посилання
- WEB API для стрес теста - https://github.com/vitalya420/ddos-test-env